{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11232473,"sourceType":"datasetVersion","datasetId":6996294}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pandas scikit-learn zxcvbn-python matplotlib seaborn joblib\n!USE_GPU=1 pip install lightgbm\n!pip install lightgbm --config-settings=--gpu","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T18:18:48.688379Z","iopub.execute_input":"2025-04-01T18:18:48.688769Z","iopub.status.idle":"2025-04-01T18:18:56.008747Z","shell.execute_reply.started":"2025-04-01T18:18:48.688743Z","shell.execute_reply":"2025-04-01T18:18:56.007833Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.3)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\nRequirement already satisfied: zxcvbn-python in /usr/local/lib/python3.10/dist-packages (4.4.24)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.5)\nRequirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.12.2)\nRequirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (1.4.2)\nRequirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.22.4->pandas) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.22.4->pandas) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.22.4->pandas) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.22.4->pandas) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.22.4->pandas) (2024.2.0)\nRequirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (4.5.0)\nRequirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.26.4)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17.0->lightgbm) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17.0->lightgbm) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17.0->lightgbm) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17.0->lightgbm) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17.0->lightgbm) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17.0->lightgbm) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17.0->lightgbm) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17.0->lightgbm) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17.0->lightgbm) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17.0->lightgbm) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17.0->lightgbm) (2024.2.0)\n\nUsage:   \n  pip3 install [options] <requirement specifier> [package-index-options] ...\n  pip3 install [options] -r <requirements file> [package-index-options] ...\n  pip3 install [options] [-e] <vcs project url> ...\n  pip3 install [options] [-e] <local project path> ...\n  pip3 install [options] <archive url/path> ...\n\nArguments to --config-settings must be of the form KEY=VAL\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import os\nimport time\nimport logging\nimport pandas as pd\nimport numpy as np\nimport joblib\nimport gc # Garbage Collector\nimport json # For saving metrics\nimport decimal # Import decimal to check type if needed\nimport datetime # Import datetime to handle potential timedelta objects\n\nprint(\"DEBUG: Basic imports done (os, time, logging, pd, np, joblib, gc, json, decimal, datetime).\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T18:18:56.010167Z","iopub.execute_input":"2025-04-01T18:18:56.010431Z","iopub.status.idle":"2025-04-01T18:18:56.015654Z","shell.execute_reply.started":"2025-04-01T18:18:56.010407Z","shell.execute_reply":"2025-04-01T18:18:56.014892Z"}},"outputs":[{"name":"stdout","text":"DEBUG: Basic imports done (os, time, logging, pd, np, joblib, gc, json, decimal, datetime).\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# --- Import Core Libraries with Error Handling ---\ntry:\n    from zxcvbn import zxcvbn\n    print(\"DEBUG: Imported zxcvbn successfully.\")\nexcept ImportError as e:\n    print(f\"DEBUG: FATAL - FAILED to import zxcvbn: {e}\")\n    exit()\n\ntry:\n    import lightgbm as lgb\n    print(\"DEBUG: Imported lightgbm successfully.\")\nexcept ImportError as e:\n    print(f\"DEBUG: FATAL - FAILED to import lightgbm: {e}\")\n    exit()\nexcept Exception as e:\n    print(f\"DEBUG: FATAL - Unknown error importing lightgbm: {e}\")\n    exit()\n\ntry:\n    from sklearn.model_selection import train_test_split\n    from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, log_loss\n    print(\"DEBUG: Imported sklearn components successfully.\")\nexcept ImportError as e:\n    print(f\"DEBUG: FATAL - FAILED to import sklearn components: {e}\")\n    exit()\n\n# --- Import Plotting Libraries ---\ntry:\n    import matplotlib.pyplot as plt\n    import seaborn as sns\n    print(\"DEBUG: Imported matplotlib and seaborn successfully.\")\n    plotting_available = True\nexcept ImportError as e:\n    print(f\"DEBUG: WARNING - FAILED to import plotting libraries (matplotlib/seaborn): {e}. Plotting will be disabled.\")\n    plt = None\n    sns = None\n    plotting_available = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T18:18:56.017250Z","iopub.execute_input":"2025-04-01T18:18:56.017493Z","iopub.status.idle":"2025-04-01T18:18:56.043855Z","shell.execute_reply.started":"2025-04-01T18:18:56.017451Z","shell.execute_reply":"2025-04-01T18:18:56.043151Z"}},"outputs":[{"name":"stdout","text":"DEBUG: Imported zxcvbn successfully.\nDEBUG: Imported lightgbm successfully.\nDEBUG: Imported sklearn components successfully.\nDEBUG: Imported matplotlib and seaborn successfully.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# --- Configuration ---\nprint(\"DEBUG: Setting up configuration...\")\n# Paths\nDATA_PATH = \"/kaggle/input/passwordrock/rockyou.txt\"\nOUTPUT_DIR = \"/kaggle/working/\" # Standard Kaggle output directory\n\n# Sample Size\nSAMPLE_SIZE = 150000\nprint(f\"DEBUG: Using SAMPLE_SIZE = {SAMPLE_SIZE}\")\n\nLOG_FILE = os.path.join(OUTPUT_DIR, \"password_strength_training.log\")\nMODEL_FILE = os.path.join(OUTPUT_DIR, \"lightgbm_password_model.joblib\")\nFEATURE_NAMES_FILE = os.path.join(OUTPUT_DIR, \"feature_names.joblib\") # Will save remaining features\nMETRICS_FILE = os.path.join(OUTPUT_DIR, \"training_metrics.json\")\nCONFUSION_MATRIX_FILE = os.path.join(OUTPUT_DIR, \"confusion_matrix.png\")\nFEATURE_IMPORTANCE_FILE = os.path.join(OUTPUT_DIR, \"feature_importance.png\") # Will show importance of remaining features\nLEARNING_CURVES_FILE = os.path.join(OUTPUT_DIR, \"learning_curves.png\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T18:18:56.044764Z","iopub.execute_input":"2025-04-01T18:18:56.044948Z","iopub.status.idle":"2025-04-01T18:18:56.063611Z","shell.execute_reply.started":"2025-04-01T18:18:56.044932Z","shell.execute_reply":"2025-04-01T18:18:56.062825Z"}},"outputs":[{"name":"stdout","text":"DEBUG: Setting up configuration...\nDEBUG: Using SAMPLE_SIZE = 150000\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# --- Model Parameters ---\nLGBM_PARAMS = {\n    'objective': 'multiclass',\n    'metric': 'multi_logloss',\n    'num_class': 5,\n    'boosting_type': 'gbdt',\n    'learning_rate': 0.02,      # <<< REDUCED learning rate\n    'num_leaves': 63,           # Keep for now, could reduce later if needed\n    'max_depth': 10,            # Keep for now, could reduce later if needed\n    'feature_fraction': 0.8,    # Keep subsampling\n    'bagging_fraction': 0.8,    # Keep subsampling\n    'bagging_freq': 5,\n    'lambda_l1': 0.3,           # <<< INCREASED L1 regularization\n    'lambda_l2': 0.3,           # <<< INCREASED L2 regularization\n    'class_weight': 'balanced', # Keep balanced weights\n    # 'min_child_samples': 20,  # Optional: Add minimum samples per leaf\n    'verbose': -1,\n    'n_jobs': -1,\n    'seed': 42,\n    'device': 'gpu',\n    'gpu_use_dp': False\n}\nprint(f\"DEBUG: LGBM Params configured. Device set to: {LGBM_PARAMS.get('device', 'cpu')}\")\nprint(f\"DEBUG: Reduced learning_rate to {LGBM_PARAMS.get('learning_rate')} and increased L1/L2 regularization to {LGBM_PARAMS.get('lambda_l1')} to reduce overfitting.\")\n# -------------------------------------------------------------","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T18:18:56.064864Z","iopub.execute_input":"2025-04-01T18:18:56.065122Z","iopub.status.idle":"2025-04-01T18:18:56.095699Z","shell.execute_reply.started":"2025-04-01T18:18:56.065103Z","shell.execute_reply":"2025-04-01T18:18:56.095038Z"}},"outputs":[{"name":"stdout","text":"DEBUG: LGBM Params configured. Device set to: gpu\nDEBUG: Reduced learning_rate to 0.02 and increased L1/L2 regularization to 0.3 to reduce overfitting.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Training Configuration\nVALIDATION_SIZE = 0.2 # 20% Val, 20% Test -> 40% total held out from initial X\nEARLY_STOPPING_ROUNDS = 50 # Keep early stopping\nRANDOM_STATE = 42\n\n# Define Features to Drop (Keep the same selection)\nFEATURES_TO_DROP = [\n    'has_spatial_match',\n    'sequence_length',\n    'sequence_space',\n    'has_l33t_match',\n    'has_date_match',\n    'has_sequence',\n    'count_upper'\n]\nprint(f\"DEBUG: Defined features to drop: {FEATURES_TO_DROP}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T18:18:56.096460Z","iopub.execute_input":"2025-04-01T18:18:56.096782Z","iopub.status.idle":"2025-04-01T18:18:56.114616Z","shell.execute_reply.started":"2025-04-01T18:18:56.096749Z","shell.execute_reply":"2025-04-01T18:18:56.113762Z"}},"outputs":[{"name":"stdout","text":"DEBUG: Defined features to drop: ['has_spatial_match', 'sequence_length', 'sequence_space', 'has_l33t_match', 'has_date_match', 'has_sequence', 'count_upper']\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Create output directory\ntry:\n    print(f\"DEBUG: Checking/creating output directory: {OUTPUT_DIR}\")\n    os.makedirs(OUTPUT_DIR, exist_ok=True)\n    print(f\"DEBUG: Output directory exists: {os.path.exists(OUTPUT_DIR)}\")\nexcept Exception as e:\n    print(f\"DEBUG: FATAL - FAILED to create output directory {OUTPUT_DIR}: {e}\")\n    exit()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T18:18:56.115587Z","iopub.execute_input":"2025-04-01T18:18:56.115839Z","iopub.status.idle":"2025-04-01T18:18:56.130379Z","shell.execute_reply.started":"2025-04-01T18:18:56.115819Z","shell.execute_reply":"2025-04-01T18:18:56.129764Z"}},"outputs":[{"name":"stdout","text":"DEBUG: Checking/creating output directory: /kaggle/working/\nDEBUG: Output directory exists: True\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# --- Logging Setup ---\ntry:\n    print(\"DEBUG: Configuring logging...\")\n    for handler in logging.root.handlers[:]: logging.root.removeHandler(handler)\n    logging.basicConfig(\n        level=logging.INFO,\n        format='%(asctime)s - %(levelname)s - %(message)s',\n        handlers=[ logging.FileHandler(LOG_FILE, mode='w'), logging.StreamHandler() ]\n    )\n    logging.info(\"--- Starting Password Strength Model Training ---\")\n    logging.info(f\"Output directory: {OUTPUT_DIR}\")\n    logging.info(f\"Using data path: {DATA_PATH}\")\n    logging.info(f\"Sample size: {SAMPLE_SIZE}\")\n    logging.info(f\"LGBM Params: {LGBM_PARAMS}\") # Log updated params\n    logging.info(f\"Features to drop: {FEATURES_TO_DROP}\")\n    print(\"DEBUG: Logging configured successfully.\")\nexcept Exception as e:\n    print(f\"DEBUG: WARNING - FAILED to configure logging: {e}. File logging disabled.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T18:18:56.131186Z","iopub.execute_input":"2025-04-01T18:18:56.131407Z","iopub.status.idle":"2025-04-01T18:18:56.158100Z","shell.execute_reply.started":"2025-04-01T18:18:56.131389Z","shell.execute_reply":"2025-04-01T18:18:56.157441Z"}},"outputs":[{"name":"stderr","text":"2025-04-01 18:18:56,149 - INFO - --- Starting Password Strength Model Training ---\n2025-04-01 18:18:56,150 - INFO - Output directory: /kaggle/working/\n2025-04-01 18:18:56,151 - INFO - Using data path: /kaggle/input/passwordrock/rockyou.txt\n2025-04-01 18:18:56,151 - INFO - Sample size: 150000\n2025-04-01 18:18:56,152 - INFO - LGBM Params: {'objective': 'multiclass', 'metric': 'multi_logloss', 'num_class': 5, 'boosting_type': 'gbdt', 'learning_rate': 0.02, 'num_leaves': 63, 'max_depth': 10, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.3, 'lambda_l2': 0.3, 'class_weight': 'balanced', 'verbose': -1, 'n_jobs': -1, 'seed': 42, 'device': 'gpu', 'gpu_use_dp': False}\n2025-04-01 18:18:56,153 - INFO - Features to drop: ['has_spatial_match', 'sequence_length', 'sequence_space', 'has_l33t_match', 'has_date_match', 'has_sequence', 'count_upper']\n","output_type":"stream"},{"name":"stdout","text":"DEBUG: Configuring logging...\nDEBUG: Logging configured successfully.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# --- Helper Functions ---\n\ndef load_data(filepath, sample_size=None, encoding='latin-1'):\n    \"\"\"Loads passwords from a text file, optionally sampling.\"\"\"\n    logging.info(f\"Attempting to load data from {filepath}...\")\n    print(f\"DEBUG: load_data called with filepath={filepath}, sample_size={sample_size}\")\n    start_time = time.time()\n    passwords = []\n    try:\n        if not os.path.exists(filepath):\n             logging.error(f\"Error: Data file not found at {filepath}\")\n             print(f\"DEBUG: File not found error for {filepath}\")\n             raise FileNotFoundError(f\"Data file not found: {filepath}\")\n\n        with open(filepath, 'r', encoding=encoding, errors='ignore') as f:\n            if sample_size is not None:\n                logging.info(\"Sampling enabled. Reading lines...\")\n                print(\"DEBUG: load_data - Sampling enabled, reading lines...\")\n                all_lines = f.readlines()\n                stripped_lines = [line.strip() for line in all_lines if line.strip()]\n                num_lines = len(stripped_lines)\n                logging.info(f\"Total non-empty lines read: {num_lines}\")\n                print(f\"DEBUG: load_data - Total non-empty lines: {num_lines}\")\n\n                if num_lines == 0:\n                     logging.warning(\"File contains no non-empty lines.\")\n                     print(\"DEBUG: load_data - WARNING: No non-empty lines found.\")\n                     return pd.DataFrame(columns=['password'])\n\n                actual_sample_size = min(sample_size, num_lines)\n                if actual_sample_size < sample_size:\n                    logging.warning(f\"Requested sample size {sample_size} > available lines {num_lines}. Using {actual_sample_size}.\")\n                    print(f\"DEBUG: load_data - Adjusting sample size to {actual_sample_size}\")\n\n                if actual_sample_size == 0:\n                    logging.warning(\"Sample size is 0. Returning empty DataFrame.\")\n                    print(\"DEBUG: load_data - Sample size is 0.\")\n                    return pd.DataFrame(columns=['password'])\n\n                if actual_sample_size == num_lines:\n                     logging.info(f\"Using all {num_lines} available lines.\")\n                     print(\"DEBUG: load_data - Using all available lines.\")\n                     passwords = stripped_lines\n                else:\n                    print(f\"DEBUG: load_data - Sampling {actual_sample_size} lines using np.random.choice...\")\n                    indices = np.random.choice(num_lines, actual_sample_size, replace=False)\n                    passwords = [stripped_lines[i] for i in indices]\n                    logging.info(f\"Sampled {len(passwords)} passwords.\")\n                    print(f\"DEBUG: load_data - Actually sampled {len(passwords)} passwords.\")\n                del all_lines, stripped_lines\n                gc.collect()\n\n            else:\n                logging.info(\"Loading full dataset (sample_size is None)...\")\n                print(\"DEBUG: load_data - Loading full dataset...\")\n                passwords = [line.strip() for line in f if line.strip()]\n\n        duration = time.time() - start_time\n        logging.info(f\"Loaded {len(passwords)} passwords in {duration:.2f} seconds.\")\n        print(f\"DEBUG: load_data - Loaded {len(passwords)} passwords in {duration:.2f}s.\")\n        if not passwords:\n             logging.warning(\"No passwords were loaded. Check file content and encoding.\")\n             print(\"DEBUG: load_data - WARNING: No passwords loaded.\")\n             return pd.DataFrame(columns=['password'])\n        return pd.DataFrame(passwords, columns=['password'])\n\n    except FileNotFoundError: raise\n    except MemoryError:\n        logging.error(f\"MemoryError loading data from {filepath}. Try reducing SAMPLE_SIZE.\", exc_info=True)\n        print(f\"DEBUG: load_data - MemoryError. Reduce SAMPLE_SIZE.\")\n        raise\n    except Exception as e:\n        logging.error(f\"Error during data loading from {filepath}: {e}\", exc_info=True)\n        print(f\"DEBUG: load_data - Exception: {e}\")\n        raise","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T18:18:56.160150Z","iopub.execute_input":"2025-04-01T18:18:56.160504Z","iopub.status.idle":"2025-04-01T18:18:56.175055Z","shell.execute_reply.started":"2025-04-01T18:18:56.160453Z","shell.execute_reply":"2025-04-01T18:18:56.174242Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# --- Feature Engineering ---\n\ndef feature_engineer(df):\n    \"\"\"Generates features for each password using zxcvbn.\"\"\"\n    logging.info(\"Starting feature engineering with zxcvbn...\")\n    print(\"DEBUG: feature_engineer called.\")\n    if df.empty or 'password' not in df.columns:\n        logging.error(\"Input DataFrame for feature engineering is empty or missing 'password' column.\")\n        print(\"DEBUG: feature_engineer - Input DataFrame empty or invalid.\")\n        return pd.DataFrame(), pd.Series(dtype='int'), []\n\n    start_time = time.time()\n    features = []\n    processed_count = 0\n    error_count = 0\n    total_passwords = len(df)\n    logging.info(f\"Processing {total_passwords} passwords for feature engineering.\")\n    print(f\"DEBUG: feature_engineer - Starting loop for {total_passwords} passwords.\")\n\n    print_interval = max(1, total_passwords // 20)\n\n    for idx, password in enumerate(df['password']):\n        if (idx + 1) % print_interval == 0:\n             print(f\"DEBUG: feature_engineer - Processing password {idx+1}/{total_passwords}\")\n\n        if pd.isna(password) or not isinstance(password, str): password = \"\"\n        is_empty_flag = 1 if len(password) == 0 else 0\n\n        try:\n            zxcvbn_input = password if password else \" \"\n            analysis = zxcvbn(zxcvbn_input)\n\n            crack_time_seconds = analysis.get('crack_times_seconds', {}).get('offline_fast_hashing_1e10_per_second', 0.0)\n            crack_time_float = 0.0\n            try: crack_time_float = float(crack_time_seconds)\n            except (ValueError, TypeError, OverflowError):\n                if crack_time_seconds != 0.0: logging.warning(f\"Could not convert crack_time_seconds '{crack_time_seconds}' to float at index {idx}. Using 0.0.\")\n            crack_time_log10 = np.log10(max(crack_time_float, 1e-12) + 1e-9)\n\n            guesses_log10 = analysis.get('guesses_log10', 0.0)\n            guesses_log10_float = 0.0\n            try: guesses_log10_float = float(guesses_log10)\n            except (ValueError, TypeError, OverflowError):\n                 if guesses_log10 != 0.0: logging.warning(f\"Could not convert guesses_log10 '{guesses_log10}' to float at index {idx}. Using 0.0.\")\n\n            calc_time_value = analysis.get('calc_time', 0.0)\n            calc_time_ms_float = 0.0\n            if isinstance(calc_time_value, (int, float, decimal.Decimal)):\n                try: calc_time_ms_float = float(calc_time_value) * 1000.0\n                except (ValueError, TypeError, OverflowError):\n                     if calc_time_value != 0.0: logging.warning(f\"Could not convert numeric calc_time '{calc_time_value}' to ms float at index {idx}.\")\n            elif hasattr(calc_time_value, 'total_seconds'):\n                 try: calc_time_ms_float = float(calc_time_value.total_seconds()) * 1000.0\n                 except Exception as e: logging.warning(f\"Could not convert timedelta-like calc_time '{calc_time_value}' to ms float at index {idx}: {e}\")\n            else:\n                 if calc_time_value != 0.0: logging.warning(f\"Unexpected type for calc_time '{type(calc_time_value)}' value '{calc_time_value}' at index {idx}. Using 0.0 ms.\")\n\n            current_sequence = analysis.get('sequence', [])\n            sequence_matches = [m for m in current_sequence if m.get('pattern') == 'sequence']\n            has_sequence_val = int(bool(sequence_matches))\n            sequence_length_val, sequence_space_val = (len(sequence_matches[0].get('token', '')), sequence_matches[0].get('sequence_space', 0)) if sequence_matches else (0, 0)\n\n            count_lower_val = sum(1 for char in password if char.islower())\n            count_upper_val = sum(1 for char in password if char.isupper())\n            count_digit_val = sum(1 for char in password if char.isdigit())\n            count_symbol_val = len(password) - (count_lower_val + count_upper_val + count_digit_val)\n\n            zxcvbn_score_val = 0 if is_empty_flag == 1 else analysis.get('score', -1)\n\n            feat = {\n                'password_length': len(password),\n                'zxcvbn_score': zxcvbn_score_val,\n                'guesses_log10': guesses_log10_float,\n                'crack_time_log10': crack_time_log10,\n                'calc_time_ms': calc_time_ms_float,\n                'has_sequence': has_sequence_val,\n                'sequence_length': sequence_length_val,\n                'sequence_space': sequence_space_val,\n                'has_dictionary_match': int(any(m.get('pattern') == 'dictionary' for m in current_sequence)),\n                'has_spatial_match': int(any(m.get('pattern') == 'spatial' for m in current_sequence)),\n                'has_repeat_match': int(any(m.get('pattern') == 'repeat' for m in current_sequence)),\n                'has_date_match': int(any(m.get('pattern') == 'date' for m in current_sequence)),\n                'has_l33t_match': int(any(m.get('l33t', False) for m in current_sequence)),\n                'count_lower': count_lower_val,\n                'count_upper': count_upper_val,\n                'count_digit': count_digit_val,\n                'count_symbol': count_symbol_val,\n                'is_empty': is_empty_flag\n            }\n            features.append(feat)\n            processed_count += 1\n\n        except OverflowError as ofe:\n             logging.warning(f\"OverflowError during zxcvbn analysis for password index {idx} ('{str(password)[:20]}...'): {ofe}. Skipping.\")\n             print(f\"DEBUG: feature_engineer - WARNING: OverflowError for index {idx}: {ofe}\")\n             error_count += 1\n             continue\n        except Exception as e:\n            logging.warning(f\"Unexpected error during feature engineering for password index {idx} ('{str(password)[:20]}...'): {type(e).__name__}: {e}\", exc_info=False)\n            print(f\"DEBUG: feature_engineer - WARNING: Unexpected error for index {idx}: {type(e).__name__}: {e}\")\n            error_count += 1\n            continue\n\n    duration = time.time() - start_time\n    logging.info(f\"Feature engineering completed in {duration:.2f} seconds.\")\n    logging.info(f\"Successfully processed: {processed_count}, Errors/Skipped: {error_count}\")\n    print(f\"DEBUG: feature_engineer - Loop finished in {duration:.2f}s. Processed: {processed_count}, Errors/Skipped: {error_count}\")\n\n    if not features:\n        logging.error(\"No features were generated.\")\n        print(\"DEBUG: feature_engineer - ERROR: No features generated.\")\n        return pd.DataFrame(), pd.Series(dtype='int'), []\n\n    feature_df = pd.DataFrame(features)\n    print(\"DEBUG: feature_engineer - Dtypes of generated feature_df:\")\n    print(feature_df.dtypes.value_counts())\n\n    for col in feature_df.select_dtypes(include=['object']).columns:\n        try:\n            feature_df[col] = pd.to_numeric(feature_df[col])\n            print(f\"DEBUG: feature_engineer - Converted object column '{col}' to numeric.\")\n        except (ValueError, TypeError):\n             logging.error(f\"Column '{col}' has object type and could not be converted to numeric. Dropping.\")\n             print(f\"DEBUG: feature_engineer - ERROR: Could not convert object column '{col}' to numeric. Dropping.\")\n             feature_df = feature_df.drop(columns=[col])\n\n    if 'zxcvbn_score' not in feature_df.columns or feature_df['zxcvbn_score'].isnull().all():\n        logging.error(\"Feature engineering resulted in DataFrame missing target 'zxcvbn_score' or target is all NaN.\")\n        print(\"DEBUG: feature_engineer - ERROR: Resulting DataFrame missing target or target is all NaN.\")\n        return pd.DataFrame(), pd.Series(dtype='int'), []\n\n    initial_rows = len(feature_df)\n    feature_df = feature_df[feature_df['zxcvbn_score'] >= 0].copy()\n    rows_after_filter = len(feature_df)\n    if rows_after_filter < initial_rows:\n        logging.warning(f\"Filtered out {initial_rows - rows_after_filter} rows with invalid zxcvbn scores (< 0).\")\n        print(f\"DEBUG: feature_engineer - Filtered {initial_rows - rows_after_filter} rows with invalid scores.\")\n\n    if feature_df.empty:\n        logging.error(\"All processed passwords resulted in invalid zxcvbn scores or were filtered out.\")\n        print(\"DEBUG: feature_engineer - ERROR: DataFrame empty after filtering invalid scores.\")\n        return pd.DataFrame(), pd.Series(dtype='int'), []\n\n    y = feature_df['zxcvbn_score'].astype(int)\n    X = feature_df.drop(columns=['zxcvbn_score'])\n\n    numeric_cols = X.select_dtypes(include=np.number).columns.tolist()\n    non_numeric_cols = list(set(X.columns) - set(numeric_cols))\n    if non_numeric_cols:\n        logging.error(f\"Non-numeric columns found in features before returning: {non_numeric_cols}. Dropping them.\")\n        print(f\"DEBUG: feature_engineer - ERROR: Dropping non-numeric columns: {non_numeric_cols}\")\n        X = X[numeric_cols]\n\n    all_feature_names = list(X.columns)\n    if not all_feature_names:\n         logging.error(\"No valid numeric features remaining after processing.\")\n         print(\"DEBUG: feature_engineer - ERROR: No numeric features left.\")\n         return pd.DataFrame(), pd.Series(dtype='int'), []\n\n    logging.info(f\"Generated {len(all_feature_names)} features initially: {all_feature_names}\")\n    print(f\"DEBUG: feature_engineer - Returning X shape: {X.shape}, y shape: {y.shape}\")\n\n    return X, y, all_feature_names","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T18:18:56.176323Z","iopub.execute_input":"2025-04-01T18:18:56.176622Z","iopub.status.idle":"2025-04-01T18:18:56.200970Z","shell.execute_reply.started":"2025-04-01T18:18:56.176593Z","shell.execute_reply":"2025-04-01T18:18:56.200178Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# --- LightGBM Definition ---\n\ndef train_lightgbm(X_train, y_train, X_val, y_val, feature_names, params):\n    \"\"\"Trains the LightGBM model with GPU support and early stopping.\"\"\"\n    logging.info(\"Starting LightGBM training...\")\n    logging.info(f\"Training with {len(feature_names)} features: {feature_names}\")\n    print(f\"DEBUG: train_lightgbm called. Train shape: {X_train.shape}, Val shape: {X_val.shape}\")\n    logging.info(f\"Using parameters: {params}\")\n    print(f\"DEBUG: train_lightgbm - Params: {params}\")\n\n    start_time = time.time()\n\n    gpu_available = False\n    if params.get('device') == 'gpu':\n        try:\n            print(\"DEBUG: train_lightgbm - Verifying GPU availability with dummy data...\")\n            num_features = X_train.shape[1]\n            if num_features == 0: raise ValueError(\"X_train has 0 features.\")\n            dummy_data = np.random.rand(10, num_features).astype(np.float32)\n            dummy_labels = np.random.randint(0, params['num_class'], 10).astype(np.float32)\n            lgb.Dataset(dummy_data, label=dummy_labels).construct()\n            print(\"DEBUG: train_lightgbm - GPU seems available.\")\n            gpu_available = True\n        except Exception as gpu_e:\n            logging.warning(f\"GPU check failed: {gpu_e}. Will attempt CPU fallback if GPU training fails.\")\n            print(f\"DEBUG: train_lightgbm - WARNING: GPU pre-check failed: {gpu_e}\")\n\n    print(\"DEBUG: train_lightgbm - Checking data types before conversion...\")\n    print(\"X_train dtypes:\\n\", X_train.dtypes.value_counts())\n    print(\"X_val dtypes:\\n\", X_val.dtypes.value_counts())\n    try:\n        X_train = X_train.astype(np.float32)\n        X_val = X_val.astype(np.float32)\n        y_train = y_train.astype(np.int32)\n        y_val = y_val.astype(np.int32)\n        print(\"DEBUG: train_lightgbm - Data types converted successfully.\")\n    except Exception as e:\n        logging.error(f\"ERROR during data type conversion before LightGBM Dataset creation: {e}\", exc_info=True)\n        print(f\"DEBUG: train_lightgbm - ERROR during astype conversion: {e}\")\n        raise\n\n    try:\n        lgb_train = lgb.Dataset(X_train, label=y_train, feature_name=feature_names)\n        lgb_val = lgb.Dataset(X_val, label=y_val, reference=lgb_train, feature_name=feature_names)\n        print(\"DEBUG: train_lightgbm - LGBM Datasets created.\")\n    except Exception as e:\n        logging.error(f\"ERROR creating LightGBM Datasets: {e}\", exc_info=True)\n        print(f\"DEBUG: train_lightgbm - ERROR creating LightGBM Datasets: {e}\")\n        raise\n\n    evals_result = {}\n    callbacks = [\n        lgb.log_evaluation(period=50), # Log every 50 rounds\n        lgb.early_stopping(stopping_rounds=EARLY_STOPPING_ROUNDS, verbose=True),\n        lgb.record_evaluation(evals_result)\n    ]\n    print(\"DEBUG: train_lightgbm - Callbacks defined.\")\n\n    model = None\n    current_params = params.copy()\n    try:\n        print(f\"DEBUG: train_lightgbm - Attempting lgb.train with device='{current_params.get('device')}'...\")\n        # Increase num_boost_round significantly due to lower learning rate\n        model = lgb.train(\n            current_params, lgb_train, num_boost_round=20000, # Increased max rounds\n            valid_sets=[lgb_train, lgb_val], valid_names=['train', 'val'],\n            callbacks=callbacks\n        )\n        print(f\"DEBUG: train_lightgbm - lgb.train completed successfully on '{current_params.get('device')}'.\")\n\n    except Exception as e:\n        logging.error(f\"LightGBM training failed on '{current_params.get('device')}': {e}\", exc_info=True)\n        print(f\"DEBUG: train_lightgbm - EXCEPTION during lgb.train on '{current_params.get('device')}': {e}\")\n        if current_params.get('device') == 'gpu':\n             logging.warning(\"GPU training failed. Attempting fallback to CPU.\")\n             print(\"DEBUG: train_lightgbm - GPU failure detected, attempting CPU fallback.\")\n             current_params['device'] = 'cpu'\n             current_params.pop('gpu_device_id', None); current_params.pop('gpu_platform_id', None); current_params.pop('gpu_use_dp', None)\n             logging.info(f\"Retrying with CPU using parameters: {current_params}\")\n             print(f\"DEBUG: train_lightgbm - Retrying with CPU params: {current_params}\")\n             try:\n                 model = lgb.train(\n                    current_params, lgb_train, num_boost_round=20000, # Increased max rounds\n                    valid_sets=[lgb_train, lgb_val], valid_names=['train', 'val'],\n                    callbacks=callbacks\n                )\n                 print(\"DEBUG: train_lightgbm - lgb.train completed successfully on CPU fallback.\")\n             except Exception as cpu_e:\n                 logging.error(f\"LightGBM training failed on CPU fallback as well: {cpu_e}\", exc_info=True)\n                 print(f\"DEBUG: train_lightgbm - EXCEPTION during CPU fallback lgb.train: {cpu_e}\")\n                 raise cpu_e\n        else:\n            raise e\n\n    if model is None:\n        logging.error(\"Model training did not complete successfully.\")\n        print(\"DEBUG: train_lightgbm - ERROR: Model object is None after training block.\")\n        raise RuntimeError(\"LightGBM model training failed to produce a model.\")\n\n    duration = time.time() - start_time\n    logging.info(f\"LightGBM training completed in {duration:.2f} seconds.\")\n    logging.info(f\"Best iteration: {model.best_iteration}\")\n\n    best_score_dict = model.best_score\n    metric_key = params['metric']\n    if isinstance(metric_key, list): metric_key = metric_key[0]\n    if best_score_dict and 'val' in best_score_dict and metric_key in best_score_dict['val']:\n        best_val_score = best_score_dict['val'][metric_key]\n        logging.info(f\"Best validation score ({metric_key}): {best_val_score:.4f}\")\n    else:\n        logging.warning(f\"Could not retrieve best validation score for metric '{metric_key}' from model.\")\n        print(f\"DEBUG: train_lightgbm - model.best_score content: {best_score_dict}\")\n\n    print(f\"DEBUG: train_lightgbm - Training finished in {duration:.2f}s.\")\n    return model, evals_result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T18:18:56.201680Z","iopub.execute_input":"2025-04-01T18:18:56.201866Z","iopub.status.idle":"2025-04-01T18:18:56.228229Z","shell.execute_reply.started":"2025-04-01T18:18:56.201849Z","shell.execute_reply":"2025-04-01T18:18:56.227628Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# --- Model Evaluation ---\n\ndef evaluate_model(model, X_test, y_test, feature_names, params, output_dir):\n    \"\"\"Evaluates the model and saves metrics and plots.\"\"\"\n    logging.info(\"Evaluating model on the test set...\")\n    logging.info(f\"Evaluating with {len(feature_names)} features: {feature_names}\")\n    print(f\"DEBUG: evaluate_model called. Test shape: {X_test.shape}\")\n    start_time = time.time()\n\n    try:\n        if set(X_test.columns) != set(feature_names):\n             logging.warning(f\"Columns mismatch between X_test ({X_test.columns.tolist()}) and feature_names ({feature_names}). Realigning.\")\n             print(f\"DEBUG: evaluate_model - Realigning X_test columns.\")\n             for col in feature_names:\n                 if col not in X_test.columns: X_test[col] = 0.0\n             X_test = X_test[feature_names]\n\n        X_test = X_test.astype(np.float32)\n        y_test = y_test.astype(np.int32)\n    except Exception as e:\n        logging.error(f\"ERROR converting test data types or aligning columns: {e}\", exc_info=True)\n        print(f\"DEBUG: evaluate_model - ERROR converting/aligning test data: {e}\")\n        raise\n\n    print(\"DEBUG: evaluate_model - Predicting probabilities...\")\n    y_pred_proba = model.predict(X_test, num_iteration=model.best_iteration)\n    print(\"DEBUG: evaluate_model - Predicting classes...\")\n    y_pred = np.argmax(y_pred_proba, axis=1)\n\n    print(\"DEBUG: evaluate_model - Calculating metrics...\")\n    num_classes = params['num_class']\n    class_labels = range(num_classes)\n    target_names = [f'Score {i}' for i in class_labels]\n\n    accuracy = accuracy_score(y_test, y_pred)\n    report = classification_report(y_test, y_pred, output_dict=True, zero_division=0, labels=class_labels, target_names=target_names)\n    try:\n        logloss = log_loss(y_test, y_pred_proba, labels=class_labels)\n    except ValueError as le:\n        logging.warning(f\"Could not calculate log_loss: {le}\")\n        print(f\"DEBUG: evaluate_model - y_test unique values: {np.unique(y_test)}\")\n        print(f\"DEBUG: evaluate_model - y_pred_proba shape: {y_pred_proba.shape}\")\n        logloss = -1.0\n\n    cm = confusion_matrix(y_test, y_pred, labels=class_labels)\n\n    metrics = {\n        'accuracy': accuracy,\n        'log_loss': logloss,\n        'classification_report': report,\n        'confusion_matrix': cm.tolist()\n    }\n\n    logging.info(f\"Test Set Evaluation:\")\n    logging.info(f\"  Accuracy: {accuracy:.4f}\")\n    logging.info(f\"  Log Loss: {logloss:.4f}\")\n    print(f\"DEBUG: evaluate_model - Test Accuracy: {accuracy:.4f}, Log Loss: {logloss:.4f}\")\n    print(f\"DEBUG: evaluate_model - Classification Report:\\n{classification_report(y_test, y_pred, zero_division=0, labels=class_labels, target_names=target_names)}\")\n\n    if plotting_available:\n        try:\n            print(\"DEBUG: evaluate_model - Plotting confusion matrix...\")\n            plt.figure(figsize=(8, 6))\n            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n                        xticklabels=[f'Pred {i}' for i in class_labels],\n                        yticklabels=[f'True {i}' for i in class_labels])\n            plt.xlabel('Predicted Label'); plt.ylabel('True Label'); plt.title('Confusion Matrix')\n            plt.tight_layout(); plt.savefig(CONFUSION_MATRIX_FILE); plt.close()\n            logging.info(f\"Saved confusion matrix to {CONFUSION_MATRIX_FILE}\")\n            print(f\"DEBUG: evaluate_model - Saved confusion matrix to {CONFUSION_MATRIX_FILE}\")\n        except Exception as plot_e:\n            logging.error(f\"Failed to plot/save confusion matrix: {plot_e}\", exc_info=True)\n            print(f\"DEBUG: evaluate_model - ERROR plotting/saving confusion matrix: {plot_e}\")\n\n        try:\n            print(\"DEBUG: evaluate_model - Plotting feature importance...\")\n            if not feature_names:\n                 print(\"DEBUG: evaluate_model - No feature names available, skipping importance plot.\")\n                 logging.warning(\"Skipping feature importance plot as feature_names list is empty.\")\n            else:\n                plt.figure(figsize=(10, max(5, len(feature_names) // 2)))\n                lgb.plot_importance(model, max_num_features=len(feature_names), importance_type='gain')\n                plt.title('LightGBM Feature Importance (Gain)')\n                plt.tight_layout()\n                plt.savefig(FEATURE_IMPORTANCE_FILE); plt.close()\n                logging.info(f\"Saved feature importance plot to {FEATURE_IMPORTANCE_FILE}\")\n                print(f\"DEBUG: evaluate_model - Saved feature importance to {FEATURE_IMPORTANCE_FILE}\")\n        except Exception as plot_e:\n            logging.error(f\"Failed to plot/save feature importance: {plot_e}\", exc_info=True)\n            print(f\"DEBUG: evaluate_model - ERROR plotting/saving feature importance: {plot_e}\")\n    else:\n        logging.warning(\"Plotting libraries not available. Skipping plot generation.\")\n        print(\"DEBUG: evaluate_model - Skipping plots as libraries are missing.\")\n\n    duration = time.time() - start_time\n    logging.info(f\"Evaluation completed in {duration:.2f} seconds.\")\n    print(f\"DEBUG: evaluate_model - Evaluation finished in {duration:.2f}s.\")\n    return metrics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T18:18:56.229066Z","iopub.execute_input":"2025-04-01T18:18:56.229337Z","iopub.status.idle":"2025-04-01T18:18:56.255195Z","shell.execute_reply.started":"2025-04-01T18:18:56.229310Z","shell.execute_reply":"2025-04-01T18:18:56.254609Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# --- Saving Training Data & Metrics ---\n\ndef save_artifacts(model, feature_names, metrics, output_dir):\n    \"\"\"Saves the trained model, feature names used, and metrics.\"\"\"\n    logging.info(\"Saving training artifacts...\")\n    print(\"DEBUG: save_artifacts called.\")\n    try:\n        print(f\"DEBUG: save_artifacts - Saving model to {MODEL_FILE}\")\n        joblib.dump(model, MODEL_FILE)\n        logging.info(f\"Model saved to {MODEL_FILE}\")\n\n        print(f\"DEBUG: save_artifacts - Saving {len(feature_names)} used feature names to {FEATURE_NAMES_FILE}\")\n        joblib.dump(feature_names, FEATURE_NAMES_FILE)\n        logging.info(f\"Used feature names saved to {FEATURE_NAMES_FILE}\")\n\n        print(f\"DEBUG: save_artifacts - Saving metrics to {METRICS_FILE}\")\n        def convert_numpy(obj):\n            if isinstance(obj, np.integer): return int(obj)\n            elif isinstance(obj, np.floating): return float(obj)\n            elif isinstance(obj, np.ndarray): return obj.tolist()\n            elif isinstance(obj, (datetime.date, datetime.datetime)): return obj.isoformat()\n            return obj\n\n        with open(METRICS_FILE, 'w') as f:\n            json.dump(metrics, f, indent=4, default=convert_numpy)\n        logging.info(f\"Metrics saved to {METRICS_FILE}\")\n        print(\"DEBUG: save_artifacts - Artifacts saved successfully.\")\n\n    except Exception as e:\n        logging.error(f\"Error saving artifacts: {e}\", exc_info=True)\n        print(f\"DEBUG: save_artifacts - EXCEPTION: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T18:18:56.256043Z","iopub.execute_input":"2025-04-01T18:18:56.256342Z","iopub.status.idle":"2025-04-01T18:18:56.286348Z","shell.execute_reply.started":"2025-04-01T18:18:56.256313Z","shell.execute_reply":"2025-04-01T18:18:56.285770Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# --- Plotting Learning Curves ---\n\ndef plot_learning_curves(evals_result, metric_key, output_file):\n    \"\"\"Plots the training and validation learning curves for the specified metric.\"\"\"\n    logging.info(f\"Plotting learning curves for metric: {metric_key}...\")\n    print(f\"DEBUG: plot_learning_curves called for metric {metric_key}.\")\n    if not evals_result:\n        logging.warning(\"No evaluation results found to plot learning curves.\")\n        print(\"DEBUG: plot_learning_curves - No evals_result data.\")\n        return\n    if not plotting_available:\n         logging.warning(\"Plotting libraries not available. Skipping learning curve plot.\")\n         print(\"DEBUG: plot_learning_curves - Skipping plot as libraries are missing.\")\n         return\n    try:\n        plt.figure(figsize=(10, 6))\n        print(f\"DEBUG: plot_learning_curves - Plotting metric: {metric_key}\")\n        lgb.plot_metric(evals_result, metric=metric_key)\n        plt.title(f'LightGBM Learning Curves ({metric_key})'); plt.ylabel('Metric Value'); plt.xlabel('Boosting Round')\n        plt.legend(); plt.grid(True); plt.tight_layout()\n        plt.savefig(output_file); plt.close()\n        logging.info(f\"Saved learning curves plot to {output_file}\")\n        print(f\"DEBUG: plot_learning_curves - Saved plot to {output_file}\")\n    except Exception as e:\n        logging.warning(f\"Could not plot learning curves for metric {metric_key}: {e}\", exc_info=True)\n        print(f\"DEBUG: plot_learning_curves - EXCEPTION plotting {metric_key}: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T18:18:56.287086Z","iopub.execute_input":"2025-04-01T18:18:56.287273Z","iopub.status.idle":"2025-04-01T18:18:56.311132Z","shell.execute_reply.started":"2025-04-01T18:18:56.287257Z","shell.execute_reply":"2025-04-01T18:18:56.310546Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# --- Main Execution ---\nif __name__ == \"__main__\":\n    print(\"DEBUG: Entering main execution block (__name__ == '__main__').\")\n    overall_start_time = time.time()\n    final_status = \"FAILED\"\n\n    try:\n        # 1. Load Data\n        print(\"DEBUG: Main - Calling load_data...\")\n        df_passwords = load_data(DATA_PATH, sample_size=SAMPLE_SIZE)\n        if df_passwords.empty: raise ValueError(\"Loaded password DataFrame is empty.\")\n        print(f\"DEBUG: Main - load_data returned DataFrame with shape: {df_passwords.shape}\")\n\n        # 2. Feature Engineering (Generates all features initially, including 'is_empty')\n        print(\"DEBUG: Main - Calling feature_engineer...\")\n        X_initial, y, initial_feature_names = feature_engineer(df_passwords)\n        if X_initial.empty or y.empty or not initial_feature_names: raise ValueError(\"Feature engineering produced empty/invalid results.\")\n        print(f\"DEBUG: Main - feature_engineer returned X_initial shape: {X_initial.shape}, y shape: {y.shape}\")\n        del df_passwords; gc.collect()\n        print(\"DEBUG: Main - df_passwords deleted, garbage collected.\")\n\n        # Apply Feature Selection *before* splitting\n        logging.info(f\"Applying feature selection. Dropping: {FEATURES_TO_DROP}\")\n        print(f\"DEBUG: Main - Applying feature selection before splitting. Dropping: {FEATURES_TO_DROP}\")\n        feature_names_used = [f for f in initial_feature_names if f not in FEATURES_TO_DROP]\n        # Ensure 'is_empty' is kept if it wasn't explicitly dropped (it shouldn't be)\n        if 'is_empty' not in feature_names_used and 'is_empty' in initial_feature_names:\n             print(\"DEBUG: Main - Ensuring 'is_empty' feature is kept.\")\n             feature_names_used.append('is_empty')\n\n        X = X_initial[feature_names_used].copy()\n        del X_initial; gc.collect()\n        print(f\"DEBUG: Main - X shape after feature selection: {X.shape}\")\n        print(f\"DEBUG: Main - Features used for splitting/training: {feature_names_used}\")\n\n        # 3. Data Splitting (using the *selected* features)\n        print(\"DEBUG: Main - Splitting data with selected features...\")\n        if X.shape[0] <= 1 or X.shape[0] != y.shape[0]: raise ValueError(f\"Invalid data shapes for splitting: X={X.shape}, y={y.shape}\")\n        min_samples_per_class = y.value_counts().min()\n        if min_samples_per_class < 2: raise ValueError(f\"Smallest class has only {min_samples_per_class} sample(s). Need >= 2 for stratified splitting.\")\n        print(f\"DEBUG: Main - Smallest class count for stratification: {min_samples_per_class}\")\n\n        # Split Train (60%), Val (20%), Test (20%)\n        X_train, X_test_val, y_train, y_test_val = train_test_split(\n            X, y, test_size=VALIDATION_SIZE * 2, random_state=RANDOM_STATE, stratify=y\n        )\n        X_val, X_test, y_val, y_test = train_test_split(\n            X_test_val, y_test_val, test_size=0.5, random_state=RANDOM_STATE, stratify=y_test_val\n        )\n        del X_test_val, y_test_val, X, y; gc.collect()\n        print(\"DEBUG: Main - Data splitting complete.\")\n        logging.info(f\"Data split complete: Train={X_train.shape[0]}, Val={X_val.shape[0]}, Test={X_test.shape[0]}\")\n        print(f\"DEBUG: Main - Final Shapes: Train={X_train.shape}, Val={X_val.shape}, Test={X_test.shape}\")\n\n        # 4. Train Model (using selected features and adjusted params)\n        print(\"DEBUG: Main - Calling train_lightgbm...\")\n        logging.info(\"Starting model training...\")\n        model, evals_result = train_lightgbm(X_train, y_train, X_val, y_val, feature_names_used, LGBM_PARAMS)\n        print(\"DEBUG: Main - train_lightgbm returned.\")\n\n        # Plot learning curves\n        metric_key_to_plot = LGBM_PARAMS.get('metric')\n        if isinstance(metric_key_to_plot, list): metric_key_to_plot = metric_key_to_plot[0]\n        elif metric_key_to_plot is None: metric_key_to_plot = 'multi_logloss'\n        print(f\"DEBUG: Main - Calling plot_learning_curves for metric '{metric_key_to_plot}'...\")\n        plot_learning_curves(evals_result, metric_key_to_plot, LEARNING_CURVES_FILE)\n        print(\"DEBUG: Main - plot_learning_curves returned.\")\n\n        # 5. Evaluate Model (using selected features)\n        print(\"DEBUG: Main - Calling evaluate_model...\")\n        test_metrics = evaluate_model(model, X_test, y_test, feature_names_used, LGBM_PARAMS, OUTPUT_DIR)\n        print(\"DEBUG: Main - evaluate_model returned.\")\n\n        # 6. Save Artifacts (save the list of features *used*)\n        print(\"DEBUG: Main - Calling save_artifacts...\")\n        save_artifacts(model, feature_names_used, test_metrics, OUTPUT_DIR)\n        print(\"DEBUG: Main - save_artifacts returned.\")\n        logging.info(f\"Feature importance plot for *used* features saved to {FEATURE_IMPORTANCE_FILE}.\")\n        print(f\"DEBUG: Main - Review {FEATURE_IMPORTANCE_FILE} for importance of remaining features.\")\n\n        # --- Example Prediction & Confidence ---\n        logging.info(\"\\n--- Example Prediction ---\")\n        print(\"\\nDEBUG: Main - Running example predictions...\")\n        example_passwords = [\"password123\", \"Summer2024\", \"Tr0ub4dor&3\", \"P@$$w0rd!\", \"5uMM3r#2024*Q\", \"12345\", \"\", \"ÐÂÐÐ‹Ð†Ð‚Ð¡â\"]\n        example_df = pd.DataFrame(example_passwords, columns=['password'])\n\n        # Feature engineer examples (generates all features, including 'is_empty')\n        X_example_full, _, example_initial_features = feature_engineer(example_df.copy())\n\n        if not X_example_full.empty:\n             # Apply the SAME feature selection as used for training\n             print(f\"DEBUG: Main - Example features generated (full), shape: {X_example_full.shape}\")\n             print(f\"DEBUG: Main - Applying feature selection to example data using: {feature_names_used}\")\n             cols_to_select = [f for f in feature_names_used if f in X_example_full.columns]\n             X_example = X_example_full[cols_to_select].copy()\n             print(f\"DEBUG: Main - Example features after selection, shape: {X_example.shape}\")\n\n             # Align columns precisely\n             print(f\"DEBUG: Main - Aligning example features with training features used: {feature_names_used}\")\n             for col in feature_names_used:\n                 if col not in X_example.columns:\n                     print(f\"DEBUG: Main - WARNING: Adding missing column '{col}' to example features with value 0.0.\")\n                     X_example[col] = 0.0\n             cols_to_drop_extra = [col for col in X_example.columns if col not in feature_names_used]\n             if cols_to_drop_extra:\n                 print(f\"DEBUG: Main - WARNING: Dropping extra columns found in example features: {cols_to_drop_extra}\")\n                 X_example = X_example.drop(columns=cols_to_drop_extra)\n\n             # Ensure order and type\n             X_example = X_example[feature_names_used]\n             X_example = X_example.astype(np.float32)\n             print(f\"DEBUG: Main - Example features aligned. Predicting...\")\n\n             pred_probs = model.predict(X_example, num_iteration=model.best_iteration)\n             pred_classes = np.argmax(pred_probs, axis=1)\n             print(\"DEBUG: Main - Example predictions done.\")\n\n             # Map results back safely using original index\n             results_map = {}\n             valid_indices = X_example.index\n             if len(valid_indices) == len(pred_classes):\n                  for i, idx in enumerate(valid_indices):\n                      pw = example_df.loc[idx, 'password']\n                      results_map[pw] = {'pred_class': pred_classes[i], 'pred_probs': pred_probs[i]}\n             else:\n                  logging.warning(\"Mismatch between number of successfully processed example passwords and predictions.\")\n                  print(\"DEBUG: Main - WARNING: Mismatch in processed example password count and prediction count.\")\n\n             for pw in example_passwords: # Iterate original list\n                 if pw in results_map:\n                     predicted_class = results_map[pw]['pred_class']\n                     probabilities = results_map[pw]['pred_probs']\n                     confidence = probabilities[predicted_class]\n                     logging.info(f\"Password: '{pw}'\")\n                     logging.info(f\"  Predicted Strength Score (0-4): {predicted_class}\")\n                     logging.info(f\"  Confidence: {confidence:.4f}\")\n                     logging.info(f\"  Class Probabilities (0-4): {[f'{p:.3f}' for p in probabilities]}\")\n                     print(f\"DEBUG: Example - PW: '{pw}', Predicted: {predicted_class}, Confidence: {confidence:.4f}\")\n                 else:\n                     logging.info(f\"Password: '{pw}'\")\n                     logging.info(\"  Prediction: Failed (feature engineering error)\")\n                     print(f\"DEBUG: Example - PW: '{pw}', Prediction: Failed\")\n\n                 # Add zxcvbn's direct feedback\n                 try:\n                     zxcvbn_pw = pw if pw else \" \"\n                     zxcvbn_analysis = zxcvbn(zxcvbn_pw)\n                     logging.info(f\"  ZXCVBN Score: {zxcvbn_analysis['score']}\")\n                     crack_display = zxcvbn_analysis.get('crack_times_display', {}).get('offline_fast_hashing_1e10_per_second', 'N/A')\n                     logging.info(f\"  ZXCVBN Est. Crack Time (offline_fast): {crack_display}\")\n                     feedback = zxcvbn_analysis.get('feedback', {})\n                     if feedback.get('warning'): logging.info(f\"  ZXCVBN Warning: {feedback['warning']}\")\n                     if feedback.get('suggestions'): logging.info(f\"  ZXCVBN Suggestions: {'; '.join(feedback['suggestions'])}\")\n                 except Exception as e:\n                     logging.warning(f\"Could not get zxcvbn details for example '{pw}': {e}\")\n                     print(f\"DEBUG: Example - zxcvbn call failed for '{pw}': {e}\")\n                 logging.info(\"-\" * 20)\n        else:\n            logging.warning(\"Could not generate features for any example passwords. Skipping example prediction.\")\n            print(\"DEBUG: Main - WARNING: Example feature generation failed for all examples.\")\n\n        final_status = \"SUCCESS\"\n\n    # --- Exception Handling ---\n    except FileNotFoundError as e:\n        logging.error(f\"CRITICAL ERROR: Input data file not found. {e}\", exc_info=True)\n        print(f\"DEBUG: Main - CRITICAL: FileNotFoundError: {e}\")\n    except ValueError as e:\n        logging.error(f\"CRITICAL ERROR: Data processing or validation issue. {e}\", exc_info=True)\n        print(f\"DEBUG: Main - CRITICAL: ValueError: {e}\")\n    except ImportError as e:\n         logging.error(f\"CRITICAL ERROR: Missing dependency. {e}.\", exc_info=True)\n         print(f\"DEBUG: Main - CRITICAL: ImportError: {e}\")\n    except MemoryError as e:\n        logging.error(f\"CRITICAL ERROR: Out of Memory. {e}. Try reducing SAMPLE_SIZE.\", exc_info=True)\n        print(f\"DEBUG: Main - CRITICAL: MemoryError: {e}\")\n    except Exception as e:\n        logging.error(f\"CRITICAL ERROR: An unexpected error occurred during main execution.\", exc_info=True)\n        print(f\"DEBUG: Main - CRITICAL: An unexpected exception occurred: {type(e).__name__}: {e}\")\n        import traceback\n        print(\"--- TRACEBACK ---\"); traceback.print_exc(); print(\"--- END TRACEBACK ---\")\n\n    # --- Final Log ---\n    finally:\n        overall_duration = time.time() - overall_start_time\n        logging.info(f\"--- Training script finished with status: {final_status} in {overall_duration:.2f} seconds ---\")\n        print(f\"\\nDEBUG: --- Script finished in {overall_duration:.2f} seconds. Status: {final_status} ---\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T18:18:56.311967Z","iopub.execute_input":"2025-04-01T18:18:56.312227Z","iopub.status.idle":"2025-04-01T18:21:33.525162Z","shell.execute_reply.started":"2025-04-01T18:18:56.312198Z","shell.execute_reply":"2025-04-01T18:21:33.524391Z"}},"outputs":[{"name":"stderr","text":"2025-04-01 18:18:56,334 - INFO - Attempting to load data from /kaggle/input/passwordrock/rockyou.txt...\n2025-04-01 18:18:56,343 - INFO - Sampling enabled. Reading lines...\n","output_type":"stream"},{"name":"stdout","text":"DEBUG: Entering main execution block (__name__ == '__main__').\nDEBUG: Main - Calling load_data...\nDEBUG: load_data called with filepath=/kaggle/input/passwordrock/rockyou.txt, sample_size=150000\nDEBUG: load_data - Sampling enabled, reading lines...\n","output_type":"stream"},{"name":"stderr","text":"2025-04-01 18:19:01,623 - INFO - Total non-empty lines read: 17974447\n","output_type":"stream"},{"name":"stdout","text":"DEBUG: load_data - Total non-empty lines: 17974447\nDEBUG: load_data - Sampling 150000 lines using np.random.choice...\n","output_type":"stream"},{"name":"stderr","text":"2025-04-01 18:19:02,519 - INFO - Sampled 150000 passwords.\n2025-04-01 18:19:03,317 - INFO - Loaded 150000 passwords in 6.98 seconds.\n2025-04-01 18:19:03,359 - INFO - Starting feature engineering with zxcvbn...\n2025-04-01 18:19:03,360 - INFO - Processing 150000 passwords for feature engineering.\n","output_type":"stream"},{"name":"stdout","text":"DEBUG: load_data - Actually sampled 150000 passwords.\nDEBUG: load_data - Loaded 150000 passwords in 6.98s.\nDEBUG: Main - load_data returned DataFrame with shape: (150000, 1)\nDEBUG: Main - Calling feature_engineer...\nDEBUG: feature_engineer called.\nDEBUG: feature_engineer - Starting loop for 150000 passwords.\nDEBUG: feature_engineer - Processing password 7500/150000\nDEBUG: feature_engineer - Processing password 15000/150000\nDEBUG: feature_engineer - Processing password 22500/150000\nDEBUG: feature_engineer - Processing password 30000/150000\nDEBUG: feature_engineer - Processing password 37500/150000\nDEBUG: feature_engineer - Processing password 45000/150000\nDEBUG: feature_engineer - Processing password 52500/150000\nDEBUG: feature_engineer - Processing password 60000/150000\nDEBUG: feature_engineer - Processing password 67500/150000\nDEBUG: feature_engineer - Processing password 75000/150000\nDEBUG: feature_engineer - Processing password 82500/150000\nDEBUG: feature_engineer - Processing password 90000/150000\nDEBUG: feature_engineer - Processing password 97500/150000\nDEBUG: feature_engineer - Processing password 105000/150000\nDEBUG: feature_engineer - Processing password 112500/150000\nDEBUG: feature_engineer - Processing password 120000/150000\nDEBUG: feature_engineer - Processing password 127500/150000\nDEBUG: feature_engineer - Processing password 135000/150000\nDEBUG: feature_engineer - Processing password 142500/150000\n","output_type":"stream"},{"name":"stderr","text":"2025-04-01 18:21:20,331 - INFO - Feature engineering completed in 136.97 seconds.\n2025-04-01 18:21:20,332 - INFO - Successfully processed: 150000, Errors/Skipped: 0\n","output_type":"stream"},{"name":"stdout","text":"DEBUG: feature_engineer - Processing password 150000/150000\nDEBUG: feature_engineer - Loop finished in 136.97s. Processed: 150000, Errors/Skipped: 0\n","output_type":"stream"},{"name":"stderr","text":"2025-04-01 18:21:21,029 - INFO - Generated 17 features initially: ['password_length', 'guesses_log10', 'crack_time_log10', 'calc_time_ms', 'has_sequence', 'sequence_length', 'sequence_space', 'has_dictionary_match', 'has_spatial_match', 'has_repeat_match', 'has_date_match', 'has_l33t_match', 'count_lower', 'count_upper', 'count_digit', 'count_symbol', 'is_empty']\n","output_type":"stream"},{"name":"stdout","text":"DEBUG: feature_engineer - Dtypes of generated feature_df:\nint64      15\nfloat64     3\nName: count, dtype: int64\nDEBUG: feature_engineer - Returning X shape: (150000, 17), y shape: (150000,)\nDEBUG: Main - feature_engineer returned X_initial shape: (150000, 17), y shape: (150000,)\n","output_type":"stream"},{"name":"stderr","text":"2025-04-01 18:21:21,344 - INFO - Applying feature selection. Dropping: ['has_spatial_match', 'sequence_length', 'sequence_space', 'has_l33t_match', 'has_date_match', 'has_sequence', 'count_upper']\n","output_type":"stream"},{"name":"stdout","text":"DEBUG: Main - df_passwords deleted, garbage collected.\nDEBUG: Main - Applying feature selection before splitting. Dropping: ['has_spatial_match', 'sequence_length', 'sequence_space', 'has_l33t_match', 'has_date_match', 'has_sequence', 'count_upper']\nDEBUG: Main - X shape after feature selection: (150000, 10)\nDEBUG: Main - Features used for splitting/training: ['password_length', 'guesses_log10', 'crack_time_log10', 'calc_time_ms', 'has_dictionary_match', 'has_repeat_match', 'count_lower', 'count_digit', 'count_symbol', 'is_empty']\nDEBUG: Main - Splitting data with selected features...\nDEBUG: Main - Smallest class count for stratification: 261\n","output_type":"stream"},{"name":"stderr","text":"2025-04-01 18:21:21,607 - INFO - Data split complete: Train=90000, Val=30000, Test=30000\n2025-04-01 18:21:21,608 - INFO - Starting model training...\n2025-04-01 18:21:21,610 - INFO - Starting LightGBM training...\n2025-04-01 18:21:21,610 - INFO - Training with 10 features: ['password_length', 'guesses_log10', 'crack_time_log10', 'calc_time_ms', 'has_dictionary_match', 'has_repeat_match', 'count_lower', 'count_digit', 'count_symbol', 'is_empty']\n2025-04-01 18:21:21,611 - INFO - Using parameters: {'objective': 'multiclass', 'metric': 'multi_logloss', 'num_class': 5, 'boosting_type': 'gbdt', 'learning_rate': 0.02, 'num_leaves': 63, 'max_depth': 10, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.3, 'lambda_l2': 0.3, 'class_weight': 'balanced', 'verbose': -1, 'n_jobs': -1, 'seed': 42, 'device': 'gpu', 'gpu_use_dp': False}\n","output_type":"stream"},{"name":"stdout","text":"DEBUG: Main - Data splitting complete.\nDEBUG: Main - Final Shapes: Train=(90000, 10), Val=(30000, 10), Test=(30000, 10)\nDEBUG: Main - Calling train_lightgbm...\nDEBUG: train_lightgbm called. Train shape: (90000, 10), Val shape: (30000, 10)\nDEBUG: train_lightgbm - Params: {'objective': 'multiclass', 'metric': 'multi_logloss', 'num_class': 5, 'boosting_type': 'gbdt', 'learning_rate': 0.02, 'num_leaves': 63, 'max_depth': 10, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.3, 'lambda_l2': 0.3, 'class_weight': 'balanced', 'verbose': -1, 'n_jobs': -1, 'seed': 42, 'device': 'gpu', 'gpu_use_dp': False}\nDEBUG: train_lightgbm - Verifying GPU availability with dummy data...\nDEBUG: train_lightgbm - GPU seems available.\nDEBUG: train_lightgbm - Checking data types before conversion...\nX_train dtypes:\n int64      7\nfloat64    3\nName: count, dtype: int64\nX_val dtypes:\n int64      7\nfloat64    3\nName: count, dtype: int64\nDEBUG: train_lightgbm - Data types converted successfully.\nDEBUG: train_lightgbm - LGBM Datasets created.\nDEBUG: train_lightgbm - Callbacks defined.\nDEBUG: train_lightgbm - Attempting lgb.train with device='gpu'...\n","output_type":"stream"},{"name":"stderr","text":"2025-04-01 18:21:21,907 - ERROR - LightGBM training failed on 'gpu': Check failed: (best_split_info.left_count) > (0) at /usr/local/src/LightGBM/lightgbm-python/src/treelearner/serial_tree_learner.cpp, line 846 .\nTraceback (most recent call last):\n  File \"<ipython-input-14-f7f306254a72>\", line 64, in train_lightgbm\n    model = lgb.train(\n  File \"/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py\", line 307, in train\n    booster.update(fobj=fobj)\n  File \"/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py\", line 4135, in update\n    _safe_call(\n  File \"/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py\", line 296, in _safe_call\n    raise LightGBMError(_LIB.LGBM_GetLastError().decode(\"utf-8\"))\nlightgbm.basic.LightGBMError: Check failed: (best_split_info.left_count) > (0) at /usr/local/src/LightGBM/lightgbm-python/src/treelearner/serial_tree_learner.cpp, line 846 .\n\n2025-04-01 18:21:21,909 - WARNING - GPU training failed. Attempting fallback to CPU.\n2025-04-01 18:21:21,910 - INFO - Retrying with CPU using parameters: {'objective': 'multiclass', 'metric': 'multi_logloss', 'num_class': 5, 'boosting_type': 'gbdt', 'learning_rate': 0.02, 'num_leaves': 63, 'max_depth': 10, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.3, 'lambda_l2': 0.3, 'class_weight': 'balanced', 'verbose': -1, 'n_jobs': -1, 'seed': 42, 'device': 'cpu'}\n","output_type":"stream"},{"name":"stdout","text":"Training until validation scores don't improve for 50 rounds\nDEBUG: train_lightgbm - EXCEPTION during lgb.train on 'gpu': Check failed: (best_split_info.left_count) > (0) at /usr/local/src/LightGBM/lightgbm-python/src/treelearner/serial_tree_learner.cpp, line 846 .\n\nDEBUG: train_lightgbm - GPU failure detected, attempting CPU fallback.\nDEBUG: train_lightgbm - Retrying with CPU params: {'objective': 'multiclass', 'metric': 'multi_logloss', 'num_class': 5, 'boosting_type': 'gbdt', 'learning_rate': 0.02, 'num_leaves': 63, 'max_depth': 10, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.3, 'lambda_l2': 0.3, 'class_weight': 'balanced', 'verbose': -1, 'n_jobs': -1, 'seed': 42, 'device': 'cpu'}\nTraining until validation scores don't improve for 50 rounds\n[50]\ttrain's multi_logloss: 0.222834\tval's multi_logloss: 0.222796\n[100]\ttrain's multi_logloss: 0.0454746\tval's multi_logloss: 0.0455765\n[150]\ttrain's multi_logloss: 0.0108288\tval's multi_logloss: 0.011098\n[200]\ttrain's multi_logloss: 0.00332316\tval's multi_logloss: 0.00388321\n[250]\ttrain's multi_logloss: 0.00162252\tval's multi_logloss: 0.00242304\n[300]\ttrain's multi_logloss: 0.00116082\tval's multi_logloss: 0.00215123\n[350]\ttrain's multi_logloss: 0.000970934\tval's multi_logloss: 0.00213719\n","output_type":"stream"},{"name":"stderr","text":"2025-04-01 18:21:32,004 - INFO - LightGBM training completed in 10.39 seconds.\n2025-04-01 18:21:32,005 - INFO - Best iteration: 343\n2025-04-01 18:21:32,006 - INFO - Best validation score (multi_logloss): 0.0021\n2025-04-01 18:21:32,010 - INFO - Plotting learning curves for metric: multi_logloss...\n","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[343]\ttrain's multi_logloss: 0.000997068\tval's multi_logloss: 0.00213135\nDEBUG: train_lightgbm - lgb.train completed successfully on CPU fallback.\nDEBUG: train_lightgbm - Training finished in 10.39s.\nDEBUG: Main - train_lightgbm returned.\nDEBUG: Main - Calling plot_learning_curves for metric 'multi_logloss'...\nDEBUG: plot_learning_curves called for metric multi_logloss.\nDEBUG: plot_learning_curves - Plotting metric: multi_logloss\n","output_type":"stream"},{"name":"stderr","text":"2025-04-01 18:21:32,231 - INFO - Saved learning curves plot to /kaggle/working/learning_curves.png\n2025-04-01 18:21:32,232 - INFO - Evaluating model on the test set...\n2025-04-01 18:21:32,233 - INFO - Evaluating with 10 features: ['password_length', 'guesses_log10', 'crack_time_log10', 'calc_time_ms', 'has_dictionary_match', 'has_repeat_match', 'count_lower', 'count_digit', 'count_symbol', 'is_empty']\n","output_type":"stream"},{"name":"stdout","text":"DEBUG: plot_learning_curves - Saved plot to /kaggle/working/learning_curves.png\nDEBUG: Main - plot_learning_curves returned.\nDEBUG: Main - Calling evaluate_model...\nDEBUG: evaluate_model called. Test shape: (30000, 10)\nDEBUG: evaluate_model - Predicting probabilities...\n","output_type":"stream"},{"name":"stderr","text":"2025-04-01 18:21:32,898 - INFO - Test Set Evaluation:\n2025-04-01 18:21:32,898 - INFO -   Accuracy: 0.9990\n2025-04-01 18:21:32,899 - INFO -   Log Loss: 0.0021\n","output_type":"stream"},{"name":"stdout","text":"DEBUG: evaluate_model - Predicting classes...\nDEBUG: evaluate_model - Calculating metrics...\nDEBUG: evaluate_model - Test Accuracy: 0.9990, Log Loss: 0.0021\nDEBUG: evaluate_model - Classification Report:\n              precision    recall  f1-score   support\n\n     Score 0       0.72      0.74      0.73        53\n     Score 1       1.00      1.00      1.00      8720\n     Score 2       1.00      1.00      1.00      9239\n     Score 3       1.00      1.00      1.00      5687\n     Score 4       1.00      1.00      1.00      6301\n\n    accuracy                           1.00     30000\n   macro avg       0.94      0.95      0.95     30000\nweighted avg       1.00      1.00      1.00     30000\n\nDEBUG: evaluate_model - Plotting confusion matrix...\n","output_type":"stream"},{"name":"stderr","text":"2025-04-01 18:21:33,157 - INFO - Saved confusion matrix to /kaggle/working/confusion_matrix.png\n2025-04-01 18:21:33,355 - INFO - Saved feature importance plot to /kaggle/working/feature_importance.png\n2025-04-01 18:21:33,355 - INFO - Evaluation completed in 1.12 seconds.\n2025-04-01 18:21:33,356 - INFO - Saving training artifacts...\n","output_type":"stream"},{"name":"stdout","text":"DEBUG: evaluate_model - Saved confusion matrix to /kaggle/working/confusion_matrix.png\nDEBUG: evaluate_model - Plotting feature importance...\nDEBUG: evaluate_model - Saved feature importance to /kaggle/working/feature_importance.png\nDEBUG: evaluate_model - Evaluation finished in 1.12s.\nDEBUG: Main - evaluate_model returned.\nDEBUG: Main - Calling save_artifacts...\nDEBUG: save_artifacts called.\nDEBUG: save_artifacts - Saving model to /kaggle/working/lightgbm_password_model.joblib\n","output_type":"stream"},{"name":"stderr","text":"2025-04-01 18:21:33,407 - INFO - Model saved to /kaggle/working/lightgbm_password_model.joblib\n2025-04-01 18:21:33,411 - INFO - Used feature names saved to /kaggle/working/feature_names.joblib\n2025-04-01 18:21:33,413 - INFO - Metrics saved to /kaggle/working/training_metrics.json\n2025-04-01 18:21:33,414 - INFO - Feature importance plot for *used* features saved to /kaggle/working/feature_importance.png.\n2025-04-01 18:21:33,414 - INFO - \n--- Example Prediction ---\n2025-04-01 18:21:33,416 - INFO - Starting feature engineering with zxcvbn...\n2025-04-01 18:21:33,417 - INFO - Processing 8 passwords for feature engineering.\n2025-04-01 18:21:33,428 - INFO - Feature engineering completed in 0.01 seconds.\n2025-04-01 18:21:33,429 - INFO - Successfully processed: 8, Errors/Skipped: 0\n2025-04-01 18:21:33,435 - INFO - Generated 17 features initially: ['password_length', 'guesses_log10', 'crack_time_log10', 'calc_time_ms', 'has_sequence', 'sequence_length', 'sequence_space', 'has_dictionary_match', 'has_spatial_match', 'has_repeat_match', 'has_date_match', 'has_l33t_match', 'count_lower', 'count_upper', 'count_digit', 'count_symbol', 'is_empty']\n2025-04-01 18:21:33,440 - INFO - Password: 'password123'\n2025-04-01 18:21:33,441 - INFO -   Predicted Strength Score (0-4): 0\n2025-04-01 18:21:33,441 - INFO -   Confidence: 0.8255\n2025-04-01 18:21:33,442 - INFO -   Class Probabilities (0-4): ['0.825', '0.172', '0.001', '0.001', '0.001']\n2025-04-01 18:21:33,445 - INFO -   ZXCVBN Score: 0\n2025-04-01 18:21:33,447 - INFO -   ZXCVBN Est. Crack Time (offline_fast): less than a second\n2025-04-01 18:21:33,448 - INFO -   ZXCVBN Warning: This is a very common password.\n2025-04-01 18:21:33,448 - INFO -   ZXCVBN Suggestions: Add another word or two. Uncommon words are better.\n2025-04-01 18:21:33,450 - INFO - --------------------\n2025-04-01 18:21:33,450 - INFO - Password: 'Summer2024'\n2025-04-01 18:21:33,451 - INFO -   Predicted Strength Score (0-4): 2\n2025-04-01 18:21:33,451 - INFO -   Confidence: 1.0000\n2025-04-01 18:21:33,453 - INFO -   Class Probabilities (0-4): ['0.000', '0.000', '1.000', '0.000', '0.000']\n2025-04-01 18:21:33,456 - INFO -   ZXCVBN Score: 2\n2025-04-01 18:21:33,457 - INFO -   ZXCVBN Est. Crack Time (offline_fast): less than a second\n2025-04-01 18:21:33,458 - INFO -   ZXCVBN Warning: This is similar to a commonly used password.\n2025-04-01 18:21:33,458 - INFO -   ZXCVBN Suggestions: Add another word or two. Uncommon words are better.; Capitalization doesn't help very much.\n2025-04-01 18:21:33,460 - INFO - --------------------\n2025-04-01 18:21:33,461 - INFO - Password: 'Tr0ub4dor&3'\n2025-04-01 18:21:33,462 - INFO -   Predicted Strength Score (0-4): 4\n2025-04-01 18:21:33,463 - INFO -   Confidence: 0.9999\n2025-04-01 18:21:33,464 - INFO -   Class Probabilities (0-4): ['0.000', '0.000', '0.000', '0.000', '1.000']\n2025-04-01 18:21:33,466 - INFO -   ZXCVBN Score: 4\n2025-04-01 18:21:33,466 - INFO -   ZXCVBN Est. Crack Time (offline_fast): 10 seconds\n2025-04-01 18:21:33,467 - INFO - --------------------\n2025-04-01 18:21:33,470 - INFO - Password: 'P@$$w0rd!'\n2025-04-01 18:21:33,471 - INFO -   Predicted Strength Score (0-4): 1\n2025-04-01 18:21:33,471 - INFO -   Confidence: 0.9999\n2025-04-01 18:21:33,472 - INFO -   Class Probabilities (0-4): ['0.000', '1.000', '0.000', '0.000', '0.000']\n2025-04-01 18:21:33,475 - INFO -   ZXCVBN Score: 1\n2025-04-01 18:21:33,476 - INFO -   ZXCVBN Est. Crack Time (offline_fast): less than a second\n2025-04-01 18:21:33,477 - INFO -   ZXCVBN Warning: This is similar to a commonly used password.\n2025-04-01 18:21:33,478 - INFO -   ZXCVBN Suggestions: Add another word or two. Uncommon words are better.; Capitalization doesn't help very much.; Predictable substitutions like '@' instead of 'a' don't help very much.\n2025-04-01 18:21:33,478 - INFO - --------------------\n2025-04-01 18:21:33,479 - INFO - Password: '5uMM3r#2024*Q'\n2025-04-01 18:21:33,480 - INFO -   Predicted Strength Score (0-4): 4\n2025-04-01 18:21:33,480 - INFO -   Confidence: 0.9999\n2025-04-01 18:21:33,481 - INFO -   Class Probabilities (0-4): ['0.000', '0.000', '0.000', '0.000', '1.000']\n2025-04-01 18:21:33,483 - INFO -   ZXCVBN Score: 4\n2025-04-01 18:21:33,484 - INFO -   ZXCVBN Est. Crack Time (offline_fast): 6 seconds\n2025-04-01 18:21:33,485 - INFO - --------------------\n2025-04-01 18:21:33,486 - INFO - Password: '12345'\n2025-04-01 18:21:33,487 - INFO -   Predicted Strength Score (0-4): 1\n2025-04-01 18:21:33,488 - INFO -   Confidence: 0.8230\n2025-04-01 18:21:33,488 - INFO -   Class Probabilities (0-4): ['0.173', '0.823', '0.002', '0.001', '0.001']\n2025-04-01 18:21:33,495 - INFO -   ZXCVBN Score: 0\n2025-04-01 18:21:33,495 - INFO -   ZXCVBN Est. Crack Time (offline_fast): less than a second\n2025-04-01 18:21:33,496 - INFO -   ZXCVBN Warning: This is a top-10 common password.\n2025-04-01 18:21:33,496 - INFO -   ZXCVBN Suggestions: Add another word or two. Uncommon words are better.\n2025-04-01 18:21:33,497 - INFO - --------------------\n2025-04-01 18:21:33,498 - INFO - Password: ''\n2025-04-01 18:21:33,499 - INFO -   Predicted Strength Score (0-4): 0\n2025-04-01 18:21:33,500 - INFO -   Confidence: 0.9533\n2025-04-01 18:21:33,500 - INFO -   Class Probabilities (0-4): ['0.953', '0.046', '0.000', '0.000', '0.000']\n2025-04-01 18:21:33,502 - INFO -   ZXCVBN Score: 0\n2025-04-01 18:21:33,503 - INFO -   ZXCVBN Est. Crack Time (offline_fast): less than a second\n2025-04-01 18:21:33,506 - INFO -   ZXCVBN Suggestions: Add another word or two. Uncommon words are better.\n2025-04-01 18:21:33,507 - INFO - --------------------\n2025-04-01 18:21:33,507 - INFO - Password: 'ÐÂÐÐ‹Ð†Ð‚Ð¡â'\n2025-04-01 18:21:33,508 - INFO -   Predicted Strength Score (0-4): 4\n2025-04-01 18:21:33,509 - INFO -   Confidence: 0.9999\n2025-04-01 18:21:33,510 - INFO -   Class Probabilities (0-4): ['0.000', '0.000', '0.000', '0.000', '1.000']\n2025-04-01 18:21:33,512 - INFO -   ZXCVBN Score: 4\n2025-04-01 18:21:33,513 - INFO -   ZXCVBN Est. Crack Time (offline_fast): 2 minutes\n2025-04-01 18:21:33,513 - INFO - --------------------\n2025-04-01 18:21:33,515 - INFO - --- Training script finished with status: SUCCESS in 157.18 seconds ---\n","output_type":"stream"},{"name":"stdout","text":"DEBUG: save_artifacts - Saving 10 used feature names to /kaggle/working/feature_names.joblib\nDEBUG: save_artifacts - Saving metrics to /kaggle/working/training_metrics.json\nDEBUG: save_artifacts - Artifacts saved successfully.\nDEBUG: Main - save_artifacts returned.\nDEBUG: Main - Review /kaggle/working/feature_importance.png for importance of remaining features.\n\nDEBUG: Main - Running example predictions...\nDEBUG: feature_engineer called.\nDEBUG: feature_engineer - Starting loop for 8 passwords.\nDEBUG: feature_engineer - Processing password 1/8\nDEBUG: feature_engineer - Processing password 2/8\nDEBUG: feature_engineer - Processing password 3/8\nDEBUG: feature_engineer - Processing password 4/8\nDEBUG: feature_engineer - Processing password 5/8\nDEBUG: feature_engineer - Processing password 6/8\nDEBUG: feature_engineer - Processing password 7/8\nDEBUG: feature_engineer - Processing password 8/8\nDEBUG: feature_engineer - Loop finished in 0.01s. Processed: 8, Errors/Skipped: 0\nDEBUG: feature_engineer - Dtypes of generated feature_df:\nint64      15\nfloat64     3\nName: count, dtype: int64\nDEBUG: feature_engineer - Returning X shape: (8, 17), y shape: (8,)\nDEBUG: Main - Example features generated (full), shape: (8, 17)\nDEBUG: Main - Applying feature selection to example data using: ['password_length', 'guesses_log10', 'crack_time_log10', 'calc_time_ms', 'has_dictionary_match', 'has_repeat_match', 'count_lower', 'count_digit', 'count_symbol', 'is_empty']\nDEBUG: Main - Example features after selection, shape: (8, 10)\nDEBUG: Main - Aligning example features with training features used: ['password_length', 'guesses_log10', 'crack_time_log10', 'calc_time_ms', 'has_dictionary_match', 'has_repeat_match', 'count_lower', 'count_digit', 'count_symbol', 'is_empty']\nDEBUG: Main - Example features aligned. Predicting...\nDEBUG: Main - Example predictions done.\nDEBUG: Example - PW: 'password123', Predicted: 0, Confidence: 0.8255\nDEBUG: Example - PW: 'Summer2024', Predicted: 2, Confidence: 1.0000\nDEBUG: Example - PW: 'Tr0ub4dor&3', Predicted: 4, Confidence: 0.9999\nDEBUG: Example - PW: 'P@$$w0rd!', Predicted: 1, Confidence: 0.9999\nDEBUG: Example - PW: '5uMM3r#2024*Q', Predicted: 4, Confidence: 0.9999\nDEBUG: Example - PW: '12345', Predicted: 1, Confidence: 0.8230\nDEBUG: Example - PW: '', Predicted: 0, Confidence: 0.9533\nDEBUG: Example - PW: 'ÐÂÐÐ‹Ð†Ð‚Ð¡â', Predicted: 4, Confidence: 0.9999\n\nDEBUG: --- Script finished in 157.18 seconds. Status: SUCCESS ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x600 with 0 Axes>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x500 with 0 Axes>"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"!zip -r /kaggle/working.zip /kaggle/working\n\nfrom IPython.display import FileLink\nFileLink(\"/kaggle/working.zip\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T18:23:31.002959Z","iopub.execute_input":"2025-04-01T18:23:31.003329Z","iopub.status.idle":"2025-04-01T18:23:31.250317Z","shell.execute_reply.started":"2025-04-01T18:23:31.003302Z","shell.execute_reply":"2025-04-01T18:23:31.249277Z"}},"outputs":[{"name":"stdout","text":"updating: kaggle/working/ (stored 0%)\nupdating: kaggle/working/password_strength_training.log (deflated 78%)\nupdating: kaggle/working/feature_importance.png (deflated 14%)\nupdating: kaggle/working/confusion_matrix.png (deflated 16%)\nupdating: kaggle/working/feature_names.joblib (deflated 23%)\nupdating: kaggle/working/lightgbm_password_model.joblib (deflated 68%)\nupdating: kaggle/working/training_metrics.json (deflated 78%)\nupdating: kaggle/working/learning_curves.png (deflated 12%)\nupdating: kaggle/working/.virtual_documents/ (stored 0%)\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"/kaggle/working.zip","text/html":"<a href='/kaggle/working.zip' target='_blank'>/kaggle/working.zip</a><br>"},"metadata":{}}],"execution_count":20}]}